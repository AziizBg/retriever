{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da89211a-d258-440e-b6a3-0c16234e99b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc4b816-97ef-4910-8f6b-83c67f19dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import json\n",
    "import gensim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from pcst_fast import pcst_fast\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfcddaf-1b0b-4e77-ae31-61d190f01748",
   "metadata": {},
   "source": [
    "# Load embedding modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "893d4130-c2ff-4c0b-b48c-768307a4bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_repo = 'sentence-transformers/all-roberta-large-v1'\n",
    "batch_size = 1024  # Adjust the batch size as needed\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_ids=None, attention_mask=None):\n",
    "        super().__init__()\n",
    "        self.data = {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"att_mask\": attention_mask,\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data[\"input_ids\"].size(0)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(index, torch.Tensor):\n",
    "            index = index.item()\n",
    "        batch_data = dict()\n",
    "        for key in self.data.keys():\n",
    "            if self.data[key] is not None:\n",
    "                batch_data[key] = self.data[key][index]\n",
    "        return batch_data\n",
    "        \n",
    "class Sentence_Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_repo):\n",
    "        super(Sentence_Transformer, self).__init__()\n",
    "        print(f\"inherit model weights from {pretrained_repo}\")\n",
    "        self.bert_model = AutoModel.from_pretrained(pretrained_repo)\n",
    "\n",
    "    def mean_pooling(self, model_output, attention_mask):\n",
    "        token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "        data_type = token_embeddings.dtype\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).to(data_type)\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    def forward(self, input_ids, att_mask):\n",
    "        bert_out = self.bert_model(input_ids=input_ids, attention_mask=att_mask)\n",
    "        sentence_embeddings = self.mean_pooling(bert_out, att_mask)\n",
    "\n",
    "        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "        return sentence_embeddings\n",
    "\n",
    "def load_sbert():\n",
    "\n",
    "    model = Sentence_Transformer(pretrained_repo)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrained_repo)\n",
    "\n",
    "    # data parallel\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f'Using {torch.cuda.device_count()} GPUs')\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model, tokenizer, device\n",
    "\n",
    "\n",
    "def sbert_text2embedding(model, tokenizer, device, text):\n",
    "    if len(text) == 0:\n",
    "        return torch.zeros((0, 1024))\n",
    "\n",
    "    encoding = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "    dataset = Dataset(input_ids=encoding.input_ids, attention_mask=encoding.attention_mask)\n",
    "\n",
    "    # DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Placeholder for storing the embeddings\n",
    "    all_embeddings = []\n",
    "\n",
    "    # Iterate through batches\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in dataloader:\n",
    "            # Move batch to the appropriate device\n",
    "            batch = {key: value.to(device) for key, value in batch.items()}\n",
    "\n",
    "            # Forward pass\n",
    "            embeddings = model(input_ids=batch[\"input_ids\"], att_mask=batch[\"att_mask\"])\n",
    "\n",
    "            # Append the embeddings to the list\n",
    "            all_embeddings.append(embeddings)\n",
    "\n",
    "    # Concatenate the embeddings from all batches\n",
    "    all_embeddings = torch.cat(all_embeddings, dim=0).cpu()\n",
    "\n",
    "    return all_embeddings\n",
    "\n",
    "load_model = {\n",
    "    'sbert': load_sbert,\n",
    "}\n",
    "\n",
    "load_text2embedding = {\n",
    "    'sbert': sbert_text2embedding,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a187b1d0-b39d-4639-bfca-fbfc503a1245",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d7415b6-98ed-4e43-adf8-d912f36abf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'sbert'\n",
    "path = '.'\n",
    "path_nodes = f'{path}/nodes'\n",
    "path_edges = f'{path}/edges'\n",
    "path_graphs = f'{path}/graphs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e89fb80-6df3-4c6d-8db4-5964d11915f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient, DataType, FieldSchema, CollectionSchema\n",
    "\n",
    "CLUSTER_ENDPOINT = (\n",
    "    \"https://in03-7a5f9d2a1aa84ef.serverless.gcp-us-west1.cloud.zilliz.com\"\n",
    ")\n",
    "API_KEY = (\n",
    "    \"a73c79fb1924d05aeb410abc0d5669293cc33be37a123953be640725aa42198ef5c1e499cc07f231977c742ad6e6977c6eddec05\"\n",
    ")\n",
    "\n",
    "milvus_client = MilvusClient(uri=CLUSTER_ENDPOINT, token=API_KEY)\n",
    "\n",
    "COLLECTION_NAME = \"graph_embeddings\"\n",
    "VECTOR_DIM      = 1024          # SBERT default; change if yours differs\n",
    "METRIC_TYPE     = \"COSINE\"     # or \"IP\" for inner-product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48433a4b-b5ba-4883-aa49-16e61620d994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the collection if it already exists (for a clean slate)\n",
    "if COLLECTION_NAME in milvus_client.list_collections():\n",
    "    milvus_client.drop_collection(COLLECTION_NAME)\n",
    "\n",
    "# Define the schema\n",
    "schema = CollectionSchema(\n",
    "    fields=[\n",
    "        FieldSchema(\n",
    "            name=\"graph_id\",\n",
    "            dtype=DataType.INT64,\n",
    "            is_primary=True,\n",
    "            auto_id=False\n",
    "        ),\n",
    "        FieldSchema(\n",
    "            name=\"embedding\",\n",
    "            dtype=DataType.FLOAT_VECTOR,\n",
    "            dim=VECTOR_DIM\n",
    "        ),\n",
    "        FieldSchema(                 # optional metadata field\n",
    "            name=\"graph_idx\",\n",
    "            dtype=DataType.INT64\n",
    "        )\n",
    "    ],\n",
    "    description=\"Mean-pooled SBERT embeddings of knowledge graphs\"\n",
    ")\n",
    "\n",
    "index_params = milvus_client.prepare_index_params()\n",
    "index_params.add_index(\"embedding\", index_type=\"IVF_FLAT\", metric_type=\"COSINE\", index_params={\"nlist\": 64})\n",
    "milvus_client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    schema=schema,\n",
    "    consistency_level=\"Strong\",\n",
    "    index_params=index_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c868ece-0fe5-4197-88f8-c5cdfad18fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 161.29it/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocessing_step_one(path):\n",
    "    # Load the graphs from the JSON file\n",
    "    with open(path+'graphs.json', 'r') as f:\n",
    "        graphs = json.load(f)\n",
    "    \n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(path_nodes, exist_ok=True)\n",
    "    os.makedirs(path_edges, exist_ok=True)\n",
    "\n",
    "    # Process each graph\n",
    "    for i, triples in enumerate(tqdm(graphs)):\n",
    "        node_map = {}   # Maps node label → node ID\n",
    "        edges = []\n",
    "    \n",
    "        for h, r, t in triples:\n",
    "            h = h.lower()\n",
    "            t = t.lower()\n",
    "            if h not in node_map:\n",
    "                node_map[h] = len(node_map)\n",
    "            if t not in node_map:\n",
    "                node_map[t] = len(node_map)\n",
    "            edges.append({'src': node_map[h], 'edge_attr': r, 'dst': node_map[t]})\n",
    "    \n",
    "        # Convert node map to DataFrame\n",
    "        nodes_df = pd.DataFrame(\n",
    "            [{'node_id': v, 'node_attr': k} for k, v in node_map.items()],\n",
    "            columns=['node_id', 'node_attr']\n",
    "        )\n",
    "    \n",
    "        # Convert edge list to DataFrame\n",
    "        edges_df = pd.DataFrame(edges, columns=['src', 'edge_attr', 'dst'])\n",
    "    \n",
    "        # Save to CSV\n",
    "        nodes_df.to_csv(f'{path_nodes}/{i}.csv', index=False)\n",
    "        edges_df.to_csv(f'{path_edges}/{i}.csv', index=False)\n",
    "\n",
    "preprocessing_step_one('./spo/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15061d64-32f8-4bad-94f8-c3d630c8119f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local knowledge base...\n",
      "inherit model weights from sentence-transformers/all-roberta-large-v1\n",
      "Embedding and storing graphs in milvusDB...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:16<00:00, 27.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 5 graph embeddings into Milvus.\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"huggingface_hub.file_download\")\n",
    "\n",
    "def preprocessing_step_two(path):\n",
    "    print(\"Loading local knowledge base...\")\n",
    "    with open(path+'graphs.json', 'r') as f:\n",
    "        graphs = json.load(f)\n",
    "\n",
    "    model, tokenizer, device = load_model[model_name]()\n",
    "    text2embedding = load_text2embedding[model_name]\n",
    "\n",
    "    print(\"Embedding and storing graphs in milvusDB...\")\n",
    "    os.makedirs(path_graphs, exist_ok=True)\n",
    "\n",
    "    milvus_vectors = []  \n",
    "\n",
    "    for index in tqdm(range(len(graphs))):\n",
    "        # --- Load nodes & edges ---\n",
    "        nodes_path = f'{path_nodes}/{index}.csv'\n",
    "        edges_path = f'{path_edges}/{index}.csv'\n",
    "        if not os.path.exists(nodes_path) or not os.path.exists(edges_path):\n",
    "            print(f'Skipping graph {index} (missing files)')\n",
    "            continue\n",
    "\n",
    "        nodes = pd.read_csv(nodes_path)\n",
    "        edges = pd.read_csv(edges_path)\n",
    "        nodes.fillna({\"node_attr\": \"\"}, inplace=True)\n",
    "\n",
    "        if len(nodes) == 0:\n",
    "            print(f'Empty graph at index {index}')\n",
    "            continue\n",
    "\n",
    "        # --- Embed node and edge attributes ---\n",
    "        x = text2embedding(model, tokenizer, device, nodes.node_attr.tolist())\n",
    "        edge_attr = text2embedding(model, tokenizer, device, edges.edge_attr.tolist())\n",
    "        edge_index = torch.LongTensor([edges.src.tolist(), edges.dst.tolist()])\n",
    "\n",
    "        # --- Save graph as torch_geometric.Data ---\n",
    "        pyg_graph = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, num_nodes=len(nodes))\n",
    "        torch.save(pyg_graph, f'{path_graphs}/{index}.pt')\n",
    "\n",
    "        # --- Compute graph-level embedding (mean of node embeddings) ---\n",
    "        graph_embedding = torch.mean(x, dim=0).cpu().tolist()\n",
    "\n",
    "        # --- Store in Milvus format: [graph_id, embedding, index] ---\n",
    "        milvus_vectors.append({\"graph_id\": index, \"embedding\": graph_embedding, \"graph_idx\": index})\n",
    "\n",
    "    # --- Final batch insert into Milvus ---\n",
    "    if milvus_vectors:\n",
    "        milvus_client.insert(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            data=milvus_vectors,\n",
    "            auto_id=False\n",
    "        )\n",
    "        milvus_client.flush(COLLECTION_NAME)\n",
    "        print(f\"Inserted {len(milvus_vectors)} graph embeddings into Milvus.\")\n",
    "    else:\n",
    "        print(\"No graphs were inserted into Milvus.\")\n",
    "\n",
    "preprocessing_step_two('./spo/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a77b0f7-b38a-44c6-b5d1-7ee7c3f97acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval_via_pcst(graph, q_emb, textual_nodes, textual_edges, topk=3, topk_e=3, cost_e=0.5):\n",
    "    c = 0.01\n",
    "    if len(textual_nodes) == 0 or len(textual_edges) == 0:\n",
    "        desc = textual_nodes.to_csv(index=False) + '\\n' + textual_edges.to_csv(index=False, columns=['src', 'edge_attr', 'dst'])\n",
    "        graph = Data(x=graph.x, edge_index=graph.edge_index, edge_attr=graph.edge_attr, num_nodes=graph.num_nodes)\n",
    "        return graph, desc\n",
    "\n",
    "    root = -1  # unrooted\n",
    "    num_clusters = 1\n",
    "    pruning = 'gw'\n",
    "    verbosity_level = 0\n",
    "    if topk > 0:\n",
    "        n_prizes = torch.nn.CosineSimilarity(dim=-1)(q_emb, graph.x)\n",
    "        topk = min(topk, graph.num_nodes)\n",
    "        _, topk_n_indices = torch.topk(n_prizes, topk, largest=True)\n",
    "\n",
    "        n_prizes = torch.zeros_like(n_prizes)\n",
    "        n_prizes[topk_n_indices] = torch.arange(topk, 0, -1).float()\n",
    "    else:\n",
    "        n_prizes = torch.zeros(graph.num_nodes)\n",
    "\n",
    "    if topk_e > 0:\n",
    "        e_prizes = torch.nn.CosineSimilarity(dim=-1)(q_emb, graph.edge_attr)\n",
    "        topk_e = min(topk_e, e_prizes.unique().size(0))\n",
    "\n",
    "        topk_e_values, _ = torch.topk(e_prizes.unique(), topk_e, largest=True)\n",
    "        e_prizes[e_prizes < topk_e_values[-1]] = 0.0\n",
    "        last_topk_e_value = topk_e\n",
    "        for k in range(topk_e):\n",
    "            indices = e_prizes == topk_e_values[k]\n",
    "            value = min((topk_e-k)/sum(indices), last_topk_e_value)\n",
    "            e_prizes[indices] = value\n",
    "            last_topk_e_value = value*(1-c)\n",
    "        # reduce the cost of the edges such that at least one edge is selected\n",
    "        cost_e = min(cost_e, e_prizes.max().item()*(1-c/2))\n",
    "    else:\n",
    "        e_prizes = torch.zeros(graph.num_edges)\n",
    "\n",
    "    costs = []\n",
    "    edges = []\n",
    "    vritual_n_prizes = []\n",
    "    virtual_edges = []\n",
    "    virtual_costs = []\n",
    "    mapping_n = {}\n",
    "    mapping_e = {}\n",
    "    for i, (src, dst) in enumerate(graph.edge_index.T.numpy()):\n",
    "        prize_e = e_prizes[i]\n",
    "        if prize_e <= cost_e:\n",
    "            mapping_e[len(edges)] = i\n",
    "            edges.append((src, dst))\n",
    "            costs.append(cost_e - prize_e)\n",
    "        else:\n",
    "            virtual_node_id = graph.num_nodes + len(vritual_n_prizes)\n",
    "            mapping_n[virtual_node_id] = i\n",
    "            virtual_edges.append((src, virtual_node_id))\n",
    "            virtual_edges.append((virtual_node_id, dst))\n",
    "            virtual_costs.append(0)\n",
    "            virtual_costs.append(0)\n",
    "            vritual_n_prizes.append(prize_e - cost_e)\n",
    "\n",
    "    prizes = np.concatenate([n_prizes, np.array(vritual_n_prizes)])\n",
    "    num_edges = len(edges)\n",
    "    if len(virtual_costs) > 0:\n",
    "        costs = np.array(costs+virtual_costs)\n",
    "        edges = np.array(edges+virtual_edges)\n",
    "\n",
    "    vertices, edges = pcst_fast(edges, prizes, costs, root, num_clusters, pruning, verbosity_level)\n",
    "\n",
    "    selected_nodes = vertices[vertices < graph.num_nodes]\n",
    "    selected_edges = [mapping_e[e] for e in edges if e < num_edges]\n",
    "    virtual_vertices = vertices[vertices >= graph.num_nodes]\n",
    "    if len(virtual_vertices) > 0:\n",
    "        virtual_vertices = vertices[vertices >= graph.num_nodes]\n",
    "        virtual_edges = [mapping_n[i] for i in virtual_vertices]\n",
    "        selected_edges = np.array(selected_edges+virtual_edges)\n",
    "\n",
    "    edge_index = graph.edge_index[:, selected_edges]\n",
    "    selected_nodes = np.unique(np.concatenate([selected_nodes, edge_index[0].numpy(), edge_index[1].numpy()]))\n",
    "\n",
    "    n = textual_nodes.iloc[selected_nodes]\n",
    "    e = textual_edges.iloc[selected_edges]\n",
    "    desc = n.to_csv(index=False)+'\\n'+e.to_csv(index=False, columns=['src', 'edge_attr', 'dst'])\n",
    "\n",
    "    mapping = {n: i for i, n in enumerate(selected_nodes.tolist())}\n",
    "\n",
    "    x = graph.x[selected_nodes]\n",
    "    edge_attr = graph.edge_attr[selected_edges]\n",
    "    src = [mapping[i] for i in edge_index[0].tolist()]\n",
    "    dst = [mapping[i] for i in edge_index[1].tolist()]\n",
    "    edge_index = torch.LongTensor([src, dst])\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, num_nodes=len(selected_nodes))\n",
    "\n",
    "    return data, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4968bf61-7aeb-4585-b812-f40aeb007800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inherit model weights from sentence-transformers/all-roberta-large-v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving subgraphs: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"huggingface_hub.file_download\")\n",
    "\n",
    "def retreival(question, k=3):\n",
    "    model, tokenizer, device = load_model[model_name]()\n",
    "    text2embedding = load_text2embedding[model_name]\n",
    "    # Encode question\n",
    "    q_emb = text2embedding(model, tokenizer, device, [question])[0]  \n",
    "\n",
    "    # Ensure collection is loaded before search\n",
    "    try:\n",
    "        milvus_client.load_collection(COLLECTION_NAME)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading collection: {e}\")\n",
    "        return [], []\n",
    "\n",
    "    # Perform similarity search in Milvus\n",
    "    search_results = milvus_client.search(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        data=[q_emb.tolist()],\n",
    "        limit=k,\n",
    "        search_params={\"metric_type\": METRIC_TYPE, \"params\": {}},\n",
    "        output_fields=[\"graph_idx\"]\n",
    "    )\n",
    "\n",
    "    # Extract graph indices from results\n",
    "    hits = search_results[0]\n",
    "    graph_indices = [hit[\"entity\"][\"graph_idx\"] for hit in hits]\n",
    "\n",
    "    # Collect subgraphs and descriptions\n",
    "    sub_graphs = []\n",
    "    descriptions = []\n",
    "\n",
    "    for index in tqdm(graph_indices, desc=\"Retrieving subgraphs\"):\n",
    "        nodes_path = f'{path_nodes}/{index}.csv'\n",
    "        edges_path = f'{path_edges}/{index}.csv'\n",
    "        graph_path = f'{path_graphs}/{index}.pt'\n",
    "\n",
    "        if not (os.path.exists(nodes_path) and os.path.exists(edges_path) and os.path.exists(graph_path)):\n",
    "            print(f\"Missing data for graph {index}\")\n",
    "            continue\n",
    "\n",
    "        nodes = pd.read_csv(nodes_path)\n",
    "        edges = pd.read_csv(edges_path)\n",
    "        if len(nodes) == 0:\n",
    "            print(f\"Empty graph at index {index}\")\n",
    "            continue\n",
    "\n",
    "        graph = torch.load(graph_path)\n",
    "\n",
    "        # Apply your custom retrieval logic (must be defined elsewhere)\n",
    "        subg, desc = retrieval_via_pcst(\n",
    "            graph=graph,\n",
    "            q_emb=q_emb,\n",
    "            textual_nodes=nodes,\n",
    "            textual_edges=edges,\n",
    "            topk=3,\n",
    "            topk_e=5,\n",
    "            cost_e=0.5\n",
    "        )\n",
    "\n",
    "        sub_graphs.append(subg)\n",
    "        descriptions.append(desc)\n",
    "\n",
    "    return sub_graphs, descriptions\n",
    "\n",
    "question = \"How does air pollution impact the treatment or worsening of asthma and COPD symptoms?\"\n",
    "question2 = \"what are asthma symptoms?\"\n",
    "subgraphs, descriptions = retreival(question2, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2ce069c-2e34-4697-a0d9-392144ddb798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_id,node_attr\n",
      "0,asthma\n",
      "16,narrowed airways\n",
      "24,harder breathing out\n",
      "30,asthma_symptoms\n",
      "129,respiratory_distress\n",
      "134,early morning symptoms\n",
      "143,breathlessness\n",
      "146,flare-ups\n",
      "165,airway irritation\n",
      "174,wheezing\n",
      "205,asthma_attack\n",
      "245,asthma attack\n",
      "257,nocturnal symptoms\n",
      "266,shortness of breath\n",
      "320,asthma exacerbation\n",
      "329,chest_tightness\n",
      "340,excessive mucus production\n",
      "345,coughing\n",
      "363,nocturnal_coughing\n",
      "369,harder_to_breathe\n",
      "370,swelling_of_airways\n",
      "371,lightheadedness\n",
      "372,worsened_asthma_symptoms\n",
      "373,dyspnea\n",
      "376,tightening_of_airways\n",
      "381,asthma symptoms\n",
      "382,worsened asthma symptoms\n",
      "\n",
      "src,edge_attr,dst\n",
      "245,occurs_with,382\n",
      "381,leads_to_complication,245\n",
      "0,has_symptom,16\n",
      "0,has_symptom,24\n",
      "0,has_symptom,30\n",
      "0,has_symptom,129\n",
      "0,has_symptom,134\n",
      "0,has_symptom,143\n",
      "0,has_symptom,146\n",
      "0,has_symptom,165\n",
      "0,has_symptom,174\n",
      "0,has_symptom,245\n",
      "0,has_symptom,257\n",
      "0,has_symptom,266\n",
      "0,has_symptom,320\n",
      "0,has_symptom,329\n",
      "0,has_symptom,340\n",
      "0,has_symptom,345\n",
      "0,has_symptom,363\n",
      "205,has_symptom,369\n",
      "205,has_symptom,370\n",
      "205,has_symptom,371\n",
      "205,has_symptom,372\n",
      "205,has_symptom,373\n",
      "205,has_symptom,329\n",
      "205,has_symptom,345\n",
      "205,has_symptom,376\n",
      "205,has_symptom,174\n",
      "\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for i in descriptions:\n",
    "    print(i)\n",
    "    print('--------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfa env",
   "language": "python",
   "name": "pfacuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
